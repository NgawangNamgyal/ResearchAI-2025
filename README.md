# ResearchAI-2025

The four libraries being used for the AI agent are requests, BeautifulSoup, os, and openai. Requests allows HTML text to be extracted from a url link which is helpful when using a query to find links related to alter magnets. BeautifulSoup turns this raw HTML into a navigable tree so that tags and attributes can be easily extracted, which helps locate the necessary information in each article. Then, that information is sent towards ChatGPT using an API(done through the openai library) with instructions to answer the original question asked. The API key is stored as an environmental variable and is read by os. 

In detail, there are three main functions being used in this script, main, get_arXiv_info, and ask_chatgpt. Starting with main, this function allows user interference by asking for a certain topic, followed by a specific question they want answered, both of which are used as inputs for the other two functions. Afterwards, get_arXiv_info uses the topic as an input for the query search, where they can extract links to articles relevant to that topic. Those links are then accessed by the requests library to provide HTML which is processed by BeautifulSoup to make reading text easier. Specifically, the abstracts of each article are taken(Editor's Note: Features to extract information from the results/discussion/summary will be developed later. However, the inconsistent formatting[e.g. lack of headers in some articles] between arXiv articles makes it difficult to do this). Finally, in the chat_gpt function, a prompt is given to ChatGPT by using the text collected from the previous function as well as the “question” input from the main function. The model used is gpt-4.1-nano as it has great reasoning capabilities while also being the most cost-efficient model, being priced at $0.10 and $0.40 respectively per million tokens for inputs and outputs.

In the future, I am planning to add a feature that remembers the articles it has already extracted information from so that in future simulations, they will skip past these articles so as to conserve resources and increase computational efficiency. Currently, each simulation scans 10 articles, although that number is easily adjustable by tweaking the value of num_papers, which is the input used for the function get_arXiv_info. Moreover, since arXiv doesn’t have a formal peer-review process(albeit they do have a moderation team), it isn’t as reputable as other journals such as Physical Review Letters. Thus, there may be a chance that non-scientific papers may slip through the moderation process and feed the AI model false information which would be undesirable. As a result, I may add a feature to include articles from other reputable journals in order to reduce this risk factor.
